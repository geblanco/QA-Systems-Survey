\documentclass{beamer}
\usepackage{pgfpages}
\usepackage{hyperref}
\usepackage[
backend=biber,
style=alphabetic,
citestyle=authoryear
]{biblatex}

\addbibresource{library.bib}

% \setbeameroption{show only notes}
\usetheme{material}

% \usePrimary{00897B}{00695C}{FFFFFF}
\usePrimaryTeal
% \useAccent{009688}{000000}
\useAccent{004D40}{000000}

\title{Core techniques of \\ \textbf{QA Systems over KBs \\ a Survey}}
\author{Guillermo Echegoyen Blanco}
\date{}

\begin{document}

\maketitle

% ToDo := TOC

\begin{frame}{Summary}
  \begin{card}
    Here goes the Summary
  \end{card}
\end{frame}

\begin{comment}
\begin{frame}{Tasks}
  \centering
  \begin{columns}
    \setbeamercolor{coloredboxstuff}{fg=white,bg=white!10!box1}
    \begin{beamercolorbox}[wd=0.33\textwidth,sep=1em]{coloredboxstuff}
      \centering
      Question Analysis
    \end{beamercolorbox}
    \setbeamercolor{coloredboxstuff}{fg=white,bg=white!10!box2}
    \begin{beamercolorbox}[wd=0.33\textwidth,sep=1em]{coloredboxstuff}
      \centering
      Phrase Mapping
    \end{beamercolorbox}
    \setbeamercolor{coloredboxstuff}{fg=white,bg=white!10!box3}
    \begin{beamercolorbox}[wd=0.33\textwidth,sep=1em]{coloredboxstuff}
      \centering
      Disambiguation
    \end{beamercolorbox}
  \end{columns}
  \begin{columns}
    \setbeamercolor{coloredboxstuff}{fg=white,bg=white!10!box4}
    \begin{beamercolorbox}[wd=0.5\textwidth,sep=1em]{coloredboxstuff}
      \centering
      Query Construction
    \end{beamercolorbox}
    \setbeamercolor{coloredboxstuff}{fg=white,bg=white!10!box5}
    \begin{beamercolorbox}[wd=0.5\textwidth,sep=1em]{coloredboxstuff}
      \centering
      Distributed Knowledge
    \end{beamercolorbox}
  \end{columns}
\end{frame}
\end{comment}

\begin{frame}{Intro}
  \begin{cardTiny}
    \begin{itemize}
      \item A Question Answering System should be able to: \\
      \textit{Understand a Natural Language Question so as to be able to answer based on some pre-known data.}
    \end{itemize}
  \end{cardTiny}
  \begin{cardTiny}
    \begin{itemize}
      \item Typically involves accepting a question and generating a SparQL query capable of extracting the information which answers the user question.
    \end{itemize}
  \end{cardTiny}
  \begin{cardTiny}
    \begin{itemize}
      \item QALD benchmark
      \item WebQuestions benchmark
      \item SimpleQuestions benchmark
    \end{itemize}
  \end{cardTiny}
\end{frame}

\begin{frame}{Tasks}
  \begin{card}
    \begin{itemize}
      \item Question Analysis
      \item Phrase Mapping
      \item Disambiguation
      \item Query Construction
      \item Distributed Knowledge
    \end{itemize}
  \end{card}
\end{frame}

% ToDo := Describe the problems here
\begin{frame}{Question Analysis \#1}
  \begin{card}
    Analyze syntactic features to extract meaningful information:
    \begin{itemize}
      \item Type of question (is it a Which, What\dots question).
      \item Multilinguality (is it in English, French\dots).
      \item Correspondance to KB entities/classes.
      \item Tokens in the sentence and it's relations.
      \item Useless words in the sentence.
    \end{itemize}
  \end{card}
\end{frame}

\begin{frame}{Question Analysis \#2}
  \begin{card}
    Techniques based on:
    \begin{itemize}
      \item Recognizing Named Entities
      \item Segmenting with $POS^{*}$ Tags
      \item Identifying dependencies using parsers
    \end{itemize}
  \end{card}
  \vspace{8em}
  POS Tag: Part-Of-Speech Tag
\end{frame}

\note[itemize]{
  % ToDo := Correct this notes
  \item Recognizing Named Entities consists in finding the entities corresponding to parts of the phrase (eg: Europe dbr:European\_Union):Which token correspond to which resource in the KB
  \item Segmenting is like tokenization of different parts of the string, where the tag is usually universal
  \item Dependencies refer to parts of the phrase which depend upon others, direct cumpliment, adjective, subjective noun\dots
}

\begin{frame}{Question Analysis \#3 - Recognizing named entities}
  \begin{card}
    Identify Named Entities and map to resource in KB
    \begin{itemize}
      \item \textit{NER} Tools: Tools from NLP, \textbf{\textit{Standford NER Tool}}. Domain specific, \textbf{low precision 51\%} (\cite{he2014a})
      \item \textit{N-Gram}: Map n-grams to KB entities. Adv: Each NE can be recognized in the KB, disadv: Dissambiguation explodes (\textbf{too much candidates}). (SINA: \cite{shekarpour2015a}, CASIA: \cite{he2014a})
      \item \textit{Entity Linking} Tools: \textbf{DBpedia Spotlight} (\cite{daiber2013a}) and \textbf{AIDA} (\cite{yosef2011a}). Recognize NE and find the underlying KB resource, dissambiguating on the way. Adv: All-in-one. Disadv: Limited service, \textbf{KB dependant}.
    \end{itemize}
  \end{card}
\end{frame}

\note{
  Identify tokens in the sentence that refer to a resource in the KB, discarding useless words.
  \begin{itemize}
    \item When grouping n-grams, if an entity is found, the n-gram is considered, else more n-grams are tried.
  \end{itemize}
  Propose n-grams with attention mechanism?
}

\begin{frame}{Question Analysis \#4 - Segmenting using POS Tagging}
  \begin{card}
    Identify which phrase correspond to instances, properties, classes\dots and which is irrelevant.
    \begin{itemize}
      \item \textit{Handmade rules}: Regular expressions depenending on question type, structure\dots. (PowerAqua \cite{lopez2012a}, Treo \cite{freitas2014a}, DEANNA \cite{yahya2013a}). Disadv: \textbf{regex built by hand}.
      \item \textit{Learning rules}: \textbf{Machine Learning} approach, train over corpus (Xser \cite{xu2014a}, UTQA \cite{pouran2016a}). Disadv: \textbf{training corpus needed}.
    \end{itemize}
  \end{card}
\end{frame}

\note{
  It is not clear how to identify the relation between different chunks of a question
}

\begin{frame}{Question Analysis \#5 - Parsers}
  \begin{card}
    Grammar based parsers to generate trees or DAGs
    \begin{itemize}
      \item \textit{Dependency grammars}: \textbf{Standford dependency parser}, word dependencies. Adv: can extract relations along with it's arguments (gAnswer \cite{zou2014a}, \textbf{PATTY} \cite{nakashole2012a})
      \item \textit{Dependencies and DAGs}: Dependencies between phrases. Disadv: \textbf{parser trained on dataset} (Xser \cite{xu2014a}).
    \end{itemize}
  \end{card}
\end{frame}

\note{
  DAG based parser operates on a phrase level, dependency grammars on a word level.
}

\begin{frame}{Question Analysis \#6 - Summary}
  \begin{card}[Which techniques to choose?]
    \begin{itemize}
      \item Xser (\textbf{trained DAG}) reports best results on \textit{QALD 4.1 \& 5}
      \item gAnswer (\textbf{Dependency grammars}) reports fastest results on \textit{QALD 3 \& 4}
    \end{itemize}

    Machine Learning approach: Can be fast enough and there is plenty of data available.
  \end{card}
\end{frame}

% ToDo := Add the problems here
\begin{frame}{Phrase Mapping \#1}
  \begin{card}
    Find the resources in the KB with the highest probability that maps to the phrase.
  \end{card}
  \begin{card}
    Problems:
    \begin{itemize}
      \item String similarity
      \item Semantic similarity
      \item Language
    \end{itemize}
  \end{card}
\end{frame}

\note{
  String similarity: very similar words, different meaning (which, witch)
  Semantic similarity: words with related semantic meaning but different writing (king, queen)
}

\begin{frame}{Phrase Mapping \#2}
  \begin{card}
    \begin{itemize}
      \item Database with lexicalization: \textit{WordNet, Wiktionary, PATTY} Expand the phrase with synonims and use that for search. Adv: High number of candidates, disadv: \textbf{Big search space}, \textbf{not very useful for domain specific mappings}.
      \item Mappings using large texts: \textbf{word2vec} semantics reflected in the associated vector. Adv: aids in the \textbf{lexical gap}, disadv: \textbf{needs training on large texts, noisy, performance}.
    \end{itemize}
  \end{card}
\end{frame}

\note{
  PATTY is a database with relational lexicalization, uses pattern synsets (is album, [[num]] album by)
}

\begin{frame}{Disambiguation}
\end{frame}
\begin{frame}{Query Construction}
\end{frame}
\begin{frame}{Distributed Knowledge}
\end{frame}

\begin{frame}{Bibliography}
  \printbibliography
\end{frame}

\end{document}
